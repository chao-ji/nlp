{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram with shuffled tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we evaluate bigram language model using a subset from brown corpus in nltk.\n",
    "\n",
    "We first train the bigram language model with the orignal bigram sequences.\n",
    "\n",
    "The trained bigram model was evaluated on \n",
    "\n",
    "1. Test corpus where invidual tokens were **shuffled**, i.e. [\"I\", \"have\", \"an\", \"apple\"] ==> [\"an\", \"have\", \"apple\", \"I\"], which results in bigram sequences [(\"an\", \"have\"), (\"have\", \"apple\"), (\"apple\", \"I\")]\n",
    "    \n",
    "2. Test corpus with the order of tokens **unchanged**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'The', u'Fulton', u'County', u'Grand', u'Jury', u'said', u'Friday', u'an', u'investigation', u'of', u\"Atlanta's\", u'recent', u'primary', u'election', u'produced', u'``', u'no', u'evidence', u\"''\", u'that', u'any', u'irregularities', u'took', u'place', u'.'], [u'The', u'jury', u'further', u'said', u'in', u'term-end', u'presentments', u'that', u'the', u'City', u'Executive', u'Committee', u',', u'which', u'had', u'over-all', u'charge', u'of', u'the', u'election', u',', u'``', u'deserves', u'the', u'praise', u'and', u'thanks', u'of', u'the', u'City', u'of', u'Atlanta', u\"''\", u'for', u'the', u'manner', u'in', u'which', u'the', u'election', u'was', u'conducted', u'.']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import itertools\n",
    "sys.path.append(\"/home/jichao/Desktop/reddit/language_model\")\n",
    "from nltk.corpus import brown\n",
    "from language_model import *\n",
    "import copy\n",
    "\n",
    "# read sentences in \"fiction\" in brown corpus\n",
    "corpus = list(brown.sents(categories=\"news\"))\n",
    "corpus = filter(lambda doc: len(doc) >= 2, corpus)\n",
    "len_corpus = len(corpus)\n",
    "\n",
    "print corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each of the ten iterations, shuffle the corpus.\n",
    "Take the first 80% as training corpus and remaining 20% as test.\n",
    "\"\"\"     \n",
    "    \n",
    "bigram_mean= []\n",
    "bigram_mean_shuffled = []\n",
    "unigram_mean = []\n",
    "unigram_mean_shuffled = []    \n",
    "    \n",
    "for k in range(10):\n",
    "    np.random.shuffle(corpus)\n",
    "\n",
    "    corpus_train = corpus[:int(len_corpus * 0.8)]\n",
    "    corpus_test = corpus[int(len_corpus * 0.8):]\n",
    "    \n",
    "    # find the list of unique tokens in training corpus, which is used \n",
    "    # to find the number of out-of-vocabulary words later    \n",
    "    corpus_train_tokens = set(itertools.chain(*corpus_train))\n",
    "    corpus_test_tokens = set(itertools.chain(*corpus_test))\n",
    "\n",
    "    # 1. Test corpus where tokens in sentences are unchanged.\n",
    "    \n",
    "    # bigram\n",
    "    bigram = Bigram(special_token=False)\n",
    "    # oov: out-of-vocabulary words\n",
    "    oov = filter(lambda token: token not in corpus_train_tokens, corpus_test_tokens)\n",
    "    # `len(set(oov))`: number of oov\n",
    "    bigram.fit(corpus_train, len(set(oov)))\n",
    "    # for each sentence in `corpus_test` (a list of str), compute the log-probability score \n",
    "    logprob = map(lambda tokens: bigram.predict(tokens), corpus_test)\n",
    "    # save the mean of the `logprob` for the `k`th iteration\n",
    "    bigram_mean.append(np.mean(logprob))\n",
    "\n",
    "    # unigram\n",
    "    # repated the above for unigram model \n",
    "    unigram = Unigram(special_token=False)\n",
    "    unigram.fit(corpus_train, len(set(oov)))\n",
    "    logprob = map(lambda tokens: unigram.predict(tokens), corpus_test)\n",
    "    unigram_mean.append(np.mean(logprob))\n",
    "\n",
    "    # shuffle tokens in sentences in test corpus\n",
    "    corpus_test_shuffled = copy.deepcopy(corpus_test)\n",
    "    for x in corpus_test_shuffled:\n",
    "        np.random.shuffle(x)\n",
    "\n",
    "    # repeat the analysis on shuffled tokens\n",
    "    # on bigram\n",
    "    logprob = map(lambda tokens: bigram.predict(tokens), corpus_test_shuffled)\n",
    "    bigram_mean_shuffled.append(np.mean(logprob))\n",
    "\n",
    "    # on unigram\n",
    "    logprob = map(lambda tokens: unigram.predict(tokens), corpus_test_shuffled)\n",
    "    unigram_mean_shuffled.append(np.mean(logprob))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'``', u'Leading', u'Nations', u'of', u'the', u'West', u'and', u'of', u'the', u'East', u'keep', u'busy', u'making', u'newer', u'nuclear', u'weapons', u'to', u'defend', u'themselves', u'in', u'the', u'event', u'the', u'constantly', u'threatening', u'nuclear', u'war', u'should', u'break', u'out', u'.']\n"
     ]
    }
   ],
   "source": [
    "print corpus_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'in', u'the', u'Leading', u'threatening', u'themselves', u'the', u'East', u'of', u'``', u'weapons', u'the', u'newer', u'.', u'event', u'nuclear', u'nuclear', u'to', u'making', u'constantly', u'of', u'defend', u'keep', u'and', u'West', u'war', u'busy', u'out', u'Nations', u'should', u'break', u'the']\n"
     ]
    }
   ],
   "source": [
    "print corpus_test_shuffled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log-prob of bigrams (order of tokens unchaged): -6.59852267966\n",
      "Average log-prob of bigrams (order of tokens shuffled): -7.85181773523\n",
      "Average log-prob of unigrams (order of tokens unchaged): -7.2025810017\n",
      "Average log-prob of unigrams (order of tokens shuffled): -7.2025810017\n"
     ]
    }
   ],
   "source": [
    "print \"Average log-prob of bigrams (order of tokens unchaged):\", np.mean(bigram_mean)\n",
    "print \"Average log-prob of bigrams (order of tokens shuffled):\", np.mean(bigram_mean_shuffled)\n",
    "print \"Average log-prob of unigrams (order of tokens unchaged):\", np.mean(unigram_mean)\n",
    "print \"Average log-prob of unigrams (order of tokens shuffled):\", np.mean(unigram_mean_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the log-prob of bigrams where the order of tokens were shuffled is much lower than the case where the order of tokens were unchanged, which makes sense because the bigram models takes into account the relative order of adjacent tokens in a sentence.\n",
    "\n",
    "In contrast, the comparison between shuffled and unchanged sequence of tokens resulted in exactly the same log-probablity, because unigram model only counts the number of unique tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle the sentences in the training corpus**\n",
    "\n",
    "Note in the previous example we shuffled the sentences in the test corpus, while keeping the training corpus as is.\n",
    "Now let's try shuffling the sentences in the training corpus while keeping the test corpus as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_mean= []\n",
    "bigram_mean_shuffled = []\n",
    "unigram_mean = []\n",
    "unigram_mean_shuffled = []    \n",
    "    \n",
    "for k in range(10):\n",
    "    np.random.shuffle(corpus)\n",
    "\n",
    "    corpus_train = corpus[:int(len_corpus * 0.8)]\n",
    "    corpus_test = corpus[int(len_corpus * 0.8):]\n",
    "    \n",
    "    # find the list of unique tokens in training corpus, which is used \n",
    "    # to find the number of out-of-vocabulary words later    \n",
    "    corpus_train_tokens = set(itertools.chain(*corpus_train))\n",
    "    corpus_test_tokens = set(itertools.chain(*corpus_test))\n",
    "\n",
    "    # 1. Test corpus where tokens in sentences are unchanged.\n",
    "    \n",
    "    # bigram\n",
    "    bigram = Bigram(special_token=False)\n",
    "    # oov: out-of-vocabulary words\n",
    "    oov = filter(lambda token: token not in corpus_train_tokens, corpus_test_tokens)\n",
    "    # `len(set(oov))`: number of oov\n",
    "    bigram.fit(corpus_train, len(set(oov)))\n",
    "    # for each sentence in `corpus_test` (a list of str), compute the log-probability score \n",
    "    logprob = map(lambda tokens: bigram.predict(tokens), corpus_test)\n",
    "    # save the mean of the `logprob` for the `k`th iteration\n",
    "    bigram_mean.append(np.mean(logprob))\n",
    "\n",
    "    # unigram\n",
    "    # repated the above for unigram model \n",
    "    unigram = Unigram(special_token=False)\n",
    "    unigram.fit(corpus_train, len(set(oov)))\n",
    "    logprob = map(lambda tokens: unigram.predict(tokens), corpus_test)\n",
    "    unigram_mean.append(np.mean(logprob))\n",
    "\n",
    "    # shuffle tokens in sentences in train corpus\n",
    "    corpus_train_shuffled = copy.deepcopy(corpus_train)\n",
    "    for x in corpus_train_shuffled:\n",
    "        np.random.shuffle(x)\n",
    "\n",
    "    # repeat the analysis on shuffled tokens\n",
    "    # on bigram\n",
    "    bigram = Bigram(special_token=False)\n",
    "    bigram.fit(corpus_train_shuffled, len(set(oov)))\n",
    "    logprob = map(lambda tokens: bigram.predict(tokens), corpus_test)\n",
    "    bigram_mean_shuffled.append(np.mean(logprob))\n",
    "\n",
    "    # on unigram\n",
    "    unigram = Unigram(special_token=False)\n",
    "    unigram.fit(corpus_train_shuffled, len(set(oov)))\n",
    "    logprob = map(lambda tokens: unigram.predict(tokens), corpus_test)\n",
    "    unigram_mean_shuffled.append(np.mean(logprob))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log-prob of bigrams (order of tokens unchaged): -6.60034228183\n",
      "Average log-prob of bigrams (order of tokens shuffled): -7.59580165101\n",
      "Average log-prob of unigrams (order of tokens unchaged): -7.19853773406\n",
      "Average log-prob of unigrams (order of tokens shuffled): -7.19853773406\n"
     ]
    }
   ],
   "source": [
    "print \"Average log-prob of bigrams (order of tokens unchaged):\", np.mean(bigram_mean)\n",
    "print \"Average log-prob of bigrams (order of tokens shuffled):\", np.mean(bigram_mean_shuffled)\n",
    "print \"Average log-prob of unigrams (order of tokens unchaged):\", np.mean(unigram_mean)\n",
    "print \"Average log-prob of unigrams (order of tokens shuffled):\", np.mean(unigram_mean_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result still holds: shuffling the training corpus resulted in lower probabilities than keeping the training corpus unchanged."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
